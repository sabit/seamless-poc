<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Speech Translation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        .container {
            background: white;
            padding: 30px;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
        }
        
        .controls {
            display: flex;
            flex-direction: column;
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .language-controls {
            display: grid;
            grid-template-columns: 1fr auto 1fr;
            gap: 15px;
            align-items: center;
        }
        
        .language-select {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        
        label {
            font-weight: 600;
            color: #555;
        }
        
        select {
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 6px;
            font-size: 16px;
            background: white;
        }
        
        .swap-btn {
            background: #007bff;
            color: white;
            border: none;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            cursor: pointer;
            font-size: 18px;
            transition: background-color 0.3s;
        }
        
        .swap-btn:hover {
            background: #0056b3;
        }
        
        .record-controls {
            text-align: center;
        }
        
        .record-btn {
            background: #007bff;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 18px;
            border-radius: 8px;
            cursor: pointer;
            transition: background-color 0.3s;
            margin: 0 10px;
        }
        
        .record-btn:hover {
            background: #0056b3;
        }
        
        .record-btn.recording {
            background: #dc3545;
            animation: pulse 1.5s infinite;
        }
        
        .record-btn.recording:hover {
            background: #c82333;
        }
        
        .record-btn:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        .status {
            text-align: center;
            padding: 15px;
            margin: 20px 0;
            border-radius: 6px;
            font-weight: 500;
        }
        
        .status.info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }
        
        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .status.warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        
        .audio-controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 20px 0;
        }
        
        .volume-control {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .volume-slider {
            width: 100px;
        }
        
        .connection-status {
            position: absolute;
            top: 10px;
            right: 10px;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 12px;
            font-weight: bold;
        }
        
        .connection-status.connected {
            background: #28a745;
            color: white;
        }
        
        .connection-status.disconnected {
            background: #dc3545;
            color: white;
        }
        
        .connection-status.connecting {
            background: #ffc107;
            color: black;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="connection-status" id="connectionStatus">Connecting...</div>
        
        <h1>üó£Ô∏è Real-time Speech Translation</h1>
        <p style="text-align: center; color: #666; margin-bottom: 30px;">
            English ‚Üî Bangla Continuous Streaming Translation
        </p>
        
        <div class="controls">
            <div class="language-controls">
                <div class="language-select">
                    <label for="sourceLanguage">From:</label>
                    <select id="sourceLanguage">
                        <option value="eng">English</option>
                        <option value="ben">Bangla</option>
                    </select>
                </div>
                
                <button class="swap-btn" id="swapBtn" title="Swap languages">‚áÑ</button>
                
                <div class="language-select">
                    <label for="targetLanguage">To:</label>
                    <select id="targetLanguage">
                        <option value="ben">Bangla</option>
                        <option value="eng">English</option>
                    </select>
                </div>
            </div>
            
            <div class="record-controls">
                <button class="record-btn" id="streamBtn">üåä Start Streaming</button>
            </div>
            
            <div class="audio-controls">
                <div class="volume-control">
                    <label for="outputVolume">Volume:</label>
                    <input type="range" id="outputVolume" class="volume-slider" min="0" max="1" step="0.1" value="0.8">
                    <span id="volumeValue">80%</span>
                </div>
            </div>
        </div>
        
        <div class="status info" id="statusMessage">
            Click "Start Streaming" for continuous real-time translation
        </div>
    </div>

    <script>
        class SpeechTranslator {
            constructor() {
                this.websocket = null;
                this.audioStream = null;
                this.isStreaming = false;
                this.audioContext = null;
                this.currentAudioSource = null;
                this.lastAudioSize = 0;
                this.lastAudioTime = 0;
                this.outputVolume = 0.8;
                this.streamingProcessor = null;
                
                this.initializeUI();
                this.connectWebSocket();
                this.enableAudioPlayback();
            }
            
            enableAudioPlayback() {
                let audioEnabled = false;
                console.log('üéµ Setting up audio playback enablement...');
                
                // Enable audio playback on first user interaction
                const enableAudio = async () => {
                    if (audioEnabled) {
                        console.log('üéµ Audio already enabled, skipping');
                        return;
                    }
                    
                    console.log('üëÜ User interaction detected - enabling audio...');
                    
                    try {
                        if (!this.audioContext) {
                            console.log('üéµ Creating AudioContext for user interaction...');
                            // Don't force 16kHz - let browser use native sample rate for better compatibility
                            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        }
                        
                        console.log('üéµ AudioContext state before resume:', this.audioContext.state);
                        console.log('üéµ AudioContext sample rate:', this.audioContext.sampleRate);
                        
                        if (this.audioContext.state === 'suspended') {
                            await this.audioContext.resume();
                            console.log('‚úÖ AudioContext resumed from user interaction');
                        }
                        
                        // Test audio capability
                        const testBuffer = this.audioContext.createBuffer(1, 1024, this.audioContext.sampleRate);
                        const testSource = this.audioContext.createBufferSource();
                        testSource.buffer = testBuffer;
                        testSource.connect(this.audioContext.destination);
                        testSource.start();
                        testSource.stop();
                        
                        audioEnabled = true;
                        console.log('üéâ Audio playback fully enabled!');
                        this.updateStatus('Audio enabled! Ready for translation', 'success');
                        
                        // Remove the event listeners after first interaction
                        document.removeEventListener('click', enableAudio);
                        document.removeEventListener('touchstart', enableAudio);
                        console.log('üóëÔ∏è Audio enablement event listeners removed');
                        
                    } catch (error) {
                        console.error('‚ùå Failed to enable audio:', error);
                        console.error('Audio enable error details:', error.stack);
                        this.updateStatus('Audio setup failed - please refresh and try again', 'error');
                    }
                };
                
                // Add event listeners for user interaction
                console.log('üëÇ Adding click/touch listeners for audio enablement');
                document.addEventListener('click', enableAudio);
                document.addEventListener('touchstart', enableAudio);
                
                // Show initial message
                this.updateStatus('Click anywhere to enable audio playback', 'warning');
            }
            
            initializeUI() {
                this.streamBtn = document.getElementById('streamBtn');
                this.swapBtn = document.getElementById('swapBtn');
                this.sourceLanguage = document.getElementById('sourceLanguage');
                this.targetLanguage = document.getElementById('targetLanguage');
                this.statusMessage = document.getElementById('statusMessage');
                this.connectionStatus = document.getElementById('connectionStatus');
                this.outputVolumeSlider = document.getElementById('outputVolume');
                this.volumeValue = document.getElementById('volumeValue');
                
                this.streamBtn.addEventListener('click', () => this.toggleStreaming());
                this.swapBtn.addEventListener('click', () => this.swapLanguages());
                
                this.outputVolumeSlider.addEventListener('input', (e) => {
                    this.outputVolume = parseFloat(e.target.value);
                    this.volumeValue.textContent = `${Math.round(this.outputVolume * 100)}%`;
                });
                
                console.log('üöÄ Streaming mode initialized');
            }
            

            
            connectWebSocket() {
                // Close existing connection if any
                if (this.websocket && this.websocket.readyState !== WebSocket.CLOSED) {
                    console.log('üîå Closing existing WebSocket connection');
                    this.websocket.close();
                }
                
                // Auto-detect WebSocket protocol and host
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const host = window.location.host;
                const wsUrl = `${protocol}//${host}/ws/stream`;
                
                console.log('üîó Attempting WebSocket connection to:', wsUrl);
                this.updateStatus('Connecting to server...', 'info');
                this.updateConnectionStatus('connecting');
                
                this.websocket = new WebSocket(wsUrl);
                
                this.websocket.onopen = () => {
                    console.log('‚úÖ WebSocket connected successfully');
                    
                    // Send streaming start message with proper language codes
                    const srcLang = this.sourceLanguage.value === 'eng' ? 'en' : 'bn';
                    const tgtLang = this.targetLanguage.value === 'eng' ? 'en' : 'bn';
                    
                    const startMessage = {
                        type: "start_stream",
                        src_lang: srcLang,
                        tgt_lang: tgtLang,
                        sample_rate: 16000
                    };
                    
                    console.log('üì§ Sending start message:', startMessage);
                    this.websocket.send(JSON.stringify(startMessage));
                    
                    // Update connection status immediately
                    this.updateConnectionStatus('connected');
                };
                
                this.websocket.onmessage = (event) => {
                    console.log('üì• WebSocket message received, type:', typeof event.data, 'size:', event.data.size || event.data.length);
                    
                    if (typeof event.data === 'string') {
                        // Handle JSON control messages
                        console.log('üìÑ JSON message received:', event.data);
                        try {
                            const msg = JSON.parse(event.data);
                            if (msg.type === 'stream_ready') {
                                console.log('üü¢ Streaming session ready - translation system active');
                                this.updateStatus('Connected! Ready to stream.', 'success');
                                this.updateConnectionStatus('connected');
                                this.streamBtn.disabled = false;
                            } else if (msg.type === 'error') {
                                console.error('‚ùå Server error:', msg.msg);
                                this.updateStatus('Server error: ' + msg.msg, 'error');
                            } else if (msg.type === 'stream_end') {
                                console.log('üèÅ Streaming session ended');
                                this.isStreaming = false;
                                this.updateUIForStreaming(false);
                            } else {
                                console.log('‚ÑπÔ∏è Other server message:', msg);
                            }
                        } catch (e) {
                            console.error('‚ùå Failed to parse server message:', e, 'Raw data:', event.data);
                        }
                    } else {
                        // Handle binary audio data (raw PCM)
                        console.log('üéµ Binary audio data received for playback, size:', event.data.byteLength || event.data.size);
                        this.playTranslatedAudio(event.data);
                    }
                };
                
                this.websocket.onclose = (event) => {
                    console.log('üî¥ WebSocket disconnected - Code:', event.code, 'Reason:', event.reason, 'Clean:', event.wasClean);
                    this.updateStatus('Disconnected from server. Trying to reconnect...', 'error');
                    this.updateConnectionStatus('disconnected');
                    this.streamBtn.disabled = true;
                    
                    // Try to reconnect after 3 seconds
                    console.log('‚è±Ô∏è Reconnecting in 3 seconds...');
                    setTimeout(() => this.connectWebSocket(), 3000);
                };
                
                this.websocket.onerror = (error) => {
                    console.error('‚ùå WebSocket error occurred:', error);
                    console.error('Error details:', {
                        type: error.type,
                        target: error.target?.readyState,
                        timestamp: new Date().toISOString()
                    });
                    this.updateStatus('Connection error. Please check your network.', 'error');
                    this.updateConnectionStatus('disconnected');
                };
            }
            

            
            async playTranslatedAudio(audioData) {
                try {
                    const now = Date.now();
                    const audioSize = audioData.size || audioData.byteLength || 0;
                    
                    // Skip if same size audio received within 2 seconds (likely duplicate)
                    if (audioSize === this.lastAudioSize && (now - this.lastAudioTime) < 2000) {
                        console.log('üîá Skipping likely duplicate audio - same size within 2s');
                        return;
                    }
                    
                    this.lastAudioSize = audioSize;
                    this.lastAudioTime = now;
                    
                    // Stop any currently playing audio to prevent overlapping
                    if (this.currentAudioSource) {
                        console.log('üõë Stopping previous audio to prevent overlap');
                        this.currentAudioSource.stop();
                        this.currentAudioSource = null;
                    }
                    
                    console.log('üéµ Processing streaming audio');
                    console.log('Audio data type:', audioData.constructor.name);
                    
                    // Handle Blob vs ArrayBuffer
                    let arrayBuffer;
                    if (audioData instanceof Blob) {
                        console.log('Converting Blob to ArrayBuffer, size:', audioData.size, 'bytes');
                        arrayBuffer = await audioData.arrayBuffer();
                    } else if (audioData instanceof ArrayBuffer) {
                        console.log('Raw ArrayBuffer received:', audioData.byteLength, 'bytes');
                        arrayBuffer = audioData;
                    } else {
                        console.error('Unexpected audio data type:', typeof audioData);
                        this.updateStatus('Invalid audio data format', 'error');
                        return;
                    }
                    
                    console.log('Final ArrayBuffer size:', arrayBuffer.byteLength, 'bytes');
                    
                    // Backend sends raw PCM int16 data at 16kHz
                    const pcmArray = new Int16Array(arrayBuffer);
                    console.log('Converted to PCM array:', pcmArray.length, 'samples');
                    
                    if (pcmArray.length === 0) {
                        console.error('No PCM samples after conversion');
                        this.updateStatus('No audio data to play', 'error');
                        return;
                    }
                    
                    // Check for valid audio data (not all zeros)
                    const nonZeroSamples = pcmArray.filter(sample => sample !== 0).length;
                    console.log('Non-zero samples:', nonZeroSamples, 'out of', pcmArray.length);
                    
                    if (nonZeroSamples === 0) {
                        console.error('Audio data contains only silence');
                        this.updateStatus('Received silent audio - translation may have failed', 'warning');
                        return;
                    }
                    
                    // Create or resume AudioContext
                    if (!this.audioContext) {
                        console.log('üéµ Creating new AudioContext');
                        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        console.log('‚úÖ AudioContext created, sample rate:', this.audioContext.sampleRate, 'state:', this.audioContext.state);
                    }
                    
                    // Resume AudioContext if suspended (required by browser policy)
                    if (this.audioContext.state === 'suspended') {
                        console.log('‚è∏Ô∏è AudioContext suspended, attempting to resume...');
                        await this.audioContext.resume();
                        console.log('‚ñ∂Ô∏è AudioContext resumed, new state:', this.audioContext.state);
                    }
                    
                    // Create AudioBuffer for raw PCM data
                    // Backend sends 16kHz audio, resample to AudioContext sample rate if needed
                    const sourceSampleRate = 16000;
                    const targetSampleRate = this.audioContext.sampleRate;
                    const resampleRatio = targetSampleRate / sourceSampleRate;
                    const outputLength = Math.floor(pcmArray.length * resampleRatio);
                    
                    console.log('üéµ Creating AudioBuffer: 1 channel,', outputLength, 'samples at', targetSampleRate, 'Hz');
                    console.log('üìä Resample ratio:', resampleRatio.toFixed(3), '(', sourceSampleRate, '->', targetSampleRate, ')');
                    
                    const audioBuffer = this.audioContext.createBuffer(1, outputLength, targetSampleRate);
                    const channelData = audioBuffer.getChannelData(0);
                    
                    // Convert int16 to float32 and resample
                    console.log('ÔøΩ Converting and resampling PCM data...');
                    let minSample = 0, maxSample = 0;
                    
                    for (let i = 0; i < outputLength; i++) {
                        // Simple linear interpolation for resampling
                        const sourceIndex = i / resampleRatio;
                        const index1 = Math.floor(sourceIndex);
                        const index2 = Math.min(index1 + 1, pcmArray.length - 1);
                        const fraction = sourceIndex - index1;
                        
                        // Interpolate between samples
                        const sample1 = pcmArray[index1] / 32768.0;
                        const sample2 = pcmArray[index2] / 32768.0;
                        const interpolatedSample = sample1 + (sample2 - sample1) * fraction;
                        
                        // Clamp to valid range
                        channelData[i] = Math.max(-1.0, Math.min(1.0, interpolatedSample));
                        minSample = Math.min(minSample, channelData[i]);
                        maxSample = Math.max(maxSample, channelData[i]);
                    }
                    console.log('üìà Audio range after conversion: min =', minSample.toFixed(3), 'max =', maxSample.toFixed(3));
                    console.log('üìä AudioBuffer created, duration:', audioBuffer.duration.toFixed(3), 'seconds');
                    
                    // Create audio source and gain node
                    console.log('üéõÔ∏è Setting up audio graph...');
                    const source = this.audioContext.createBufferSource();
                    const gainNode = this.audioContext.createGain();
                    
                    source.buffer = audioBuffer;
                    gainNode.gain.value = this.outputVolume;
                    console.log('üîä Volume set to:', (this.outputVolume * 100).toFixed(0) + '%');
                    
                    // Connect audio graph
                    source.connect(gainNode);
                    gainNode.connect(this.audioContext.destination);
                    console.log('üîó Audio graph connected: Source ‚Üí Gain ‚Üí Destination');
                    
                    // Store reference to current audio source for stopping if needed
                    this.currentAudioSource = source;
                    
                    // Add event listeners
                    source.onended = () => {
                        console.log('üèÅ Audio playback finished successfully');
                        this.currentAudioSource = null;
                        this.updateStatus('Ready for next translation', 'success');
                    };
                    
                    source.onerror = (error) => {
                        console.error('‚ùå Audio source error:', error);
                        this.currentAudioSource = null;
                    };
                    
                    // Start playback
                    console.log('‚ñ∂Ô∏è Starting audio playback...');
                    source.start(0);
                    
                    console.log('üéµ Playing translated audio:', audioBuffer.duration.toFixed(2), 'seconds');
                    this.updateStatus(`üîä Playing translation (${audioBuffer.duration.toFixed(1)}s)`, 'success');
                    
                } catch (error) {
                    console.error('Audio playback error:', error);
                    this.updateStatus(`Playback error: ${error.message}`, 'error');
                    
                    // Detailed error logging
                    if (error.name === 'NotAllowedError') {
                        console.error('Audio playback not allowed - user interaction required');
                        this.updateStatus('Click to enable audio playback', 'error');
                    } else if (error.name === 'NotSupportedError') {
                        console.error('Audio format not supported');
                        this.updateStatus('Audio format not supported by browser', 'error');
                    }
                }
            }
            

            
            async toggleStreaming() {
                if (!this.isStreaming) {
                    // Ensure WebSocket is connected before starting streaming
                    if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
                        this.updateStatus('Connecting to server...', 'info');
                        this.connectWebSocket();
                        
                        // Wait for connection or timeout
                        let attempts = 0;
                        while ((!this.websocket || this.websocket.readyState !== WebSocket.OPEN) && attempts < 50) {
                            await new Promise(resolve => setTimeout(resolve, 100));
                            attempts++;
                        }
                        
                        if (!this.websocket || this.websocket.readyState !== WebSocket.OPEN) {
                            this.updateStatus('Failed to connect to server', 'error');
                            return;
                        }
                    }
                    
                    await this.startStreaming();
                } else {
                    this.stopStreaming();
                }
            }
            
            async startStreaming() {
                try {
                    console.log('üåä Starting continuous streaming...');
                    
                    // Set streaming flag first
                    this.isStreaming = true;
                    this.updateUIForStreaming(true);
                    
                    // Get microphone access with speech-optimized constraints
                    this.audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: true,
                            googEchoCancellation: true,
                            googAutoGainControl: true,
                            googNoiseSuppression: true,
                            googHighpassFilter: true
                        }
                    });
                    
                    console.log('‚úÖ Microphone access granted for streaming');
                    console.log('üé§ Audio stream tracks:', this.audioStream.getTracks().length);
                    
                    // Create AudioContext for processing - use browser's native sample rate
                    if (!this.audioContext) {
                        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                        console.log('üéµ AudioContext created with sample rate:', this.audioContext.sampleRate);
                    }
                    
                    if (this.audioContext.state === 'suspended') {
                        await this.audioContext.resume();
                        console.log('‚ñ∂Ô∏è AudioContext resumed');
                    }
                    
                    // Create MediaStreamAudioSourceNode
                    const source = this.audioContext.createMediaStreamSource(this.audioStream);
                    console.log('üéôÔ∏è Audio source node created');
                    
                    // Create ScriptProcessorNode for audio processing
                    const processor = this.audioContext.createScriptProcessor(4096, 1, 1);
                    console.log('üîÑ Script processor created with buffer size: 4096');
                    
                    let chunkCount = 0;
                    let speechBuffer = [];
                    let silenceCounter = 0;
                    
                    processor.onaudioprocess = (event) => {
                        if (this.isStreaming && this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                            const inputData = event.inputBuffer.getChannelData(0);
                            
                            // Check audio level and quality to avoid sending silence or noise
                            const rms = Math.sqrt(inputData.reduce((sum, sample) => sum + sample * sample, 0) / inputData.length);
                            const maxAmplitude = Math.max(...inputData.map(Math.abs));
                            
                            // Simple voice activity detection
                            const isSpeech = rms > 0.03 && maxAmplitude > 0.08;
                            
                            if (isSpeech) {
                                silenceCounter = 0;
                                speechBuffer.push(...inputData);
                                
                                // Send when we have enough speech data (about 0.5 seconds)
                                if (speechBuffer.length >= 8000) {
                                    // Convert accumulated speech to int16
                                    const int16Data = new Int16Array(speechBuffer.length);
                                    for (let i = 0; i < speechBuffer.length; i++) {
                                        int16Data[i] = Math.max(-32768, Math.min(32767, speechBuffer[i] * 32767));
                                    }
                                    
                                    // Send speech chunk to server
                                    try {
                                        this.websocket.send(int16Data.buffer);
                                        chunkCount++;
                                        console.log(`üì§ Sent speech chunk ${chunkCount}, ${speechBuffer.length} samples, RMS: ${rms.toFixed(4)}`);
                                        
                                        // Clear buffer after sending
                                        speechBuffer = [];
                                    } catch (error) {
                                        console.error('‚ùå Error sending speech chunk:', error);
                                    }
                                }
                            } else {
                                // Track silence
                                silenceCounter++;
                                
                                // If we have accumulated speech and hit silence, send it
                                if (speechBuffer.length > 4000 && silenceCounter > 3) { // 0.25s of speech + some silence
                                    const int16Data = new Int16Array(speechBuffer.length);
                                    for (let i = 0; i < speechBuffer.length; i++) {
                                        int16Data[i] = Math.max(-32768, Math.min(32767, speechBuffer[i] * 32767));
                                    }
                                    
                                    try {
                                        this.websocket.send(int16Data.buffer);
                                        chunkCount++;
                                        console.log(`üì§ Sent final speech chunk ${chunkCount}, ${speechBuffer.length} samples`);
                                        speechBuffer = [];
                                    } catch (error) {
                                        console.error('‚ùå Error sending final speech chunk:', error);
                                    }
                                }
                            }
                        }
                    };
                    
                    // Connect audio graph
                    source.connect(processor);
                    processor.connect(this.audioContext.destination);
                    
                    this.streamingProcessor = processor;
                    
                    console.log('üåä Streaming started successfully');
                    this.updateStatus('üåä Streaming... Speak continuously!', 'info');
                    
                } catch (error) {
                    console.error('Streaming error:', error);
                    this.updateStatus('Microphone access denied or streaming setup failed', 'error');
                }
            }
            
            stopStreaming() {
                console.log('‚èπÔ∏è Stopping streaming...');
                
                this.isStreaming = false;
                
                if (this.streamingProcessor) {
                    this.streamingProcessor.disconnect();
                    this.streamingProcessor = null;
                }
                
                if (this.audioStream) {
                    this.audioStream.getTracks().forEach(track => track.stop());
                    this.audioStream = null;
                }
                
                // Send stop message to server
                if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                    this.websocket.send(JSON.stringify({ type: "stop_stream" }));
                }
                
                this.updateUIForStreaming(false);
                console.log('‚úÖ Streaming stopped');
                this.updateStatus('Streaming stopped. Click "Start Streaming" to resume.', 'info');
            }
            
            updateUIForStreaming(isActive) {
                if (isActive) {
                    this.streamBtn.textContent = '‚èπÔ∏è Stop Streaming';
                    this.streamBtn.classList.add('recording');
                } else {
                    this.streamBtn.textContent = 'üåä Start Streaming';
                    this.streamBtn.classList.remove('recording');
                }
            }
            
            swapLanguages() {
                const sourceValue = this.sourceLanguage.value;
                const targetValue = this.targetLanguage.value;
                
                console.log('üîÑ Swapping languages:', sourceValue, '‚ÜîÔ∏è', targetValue);
                
                this.sourceLanguage.value = targetValue;
                this.targetLanguage.value = sourceValue;
                
                console.log('‚úÖ Languages swapped successfully');
                this.updateStatus('Languages swapped!', 'info');
                
                // If streaming is active, restart with new languages
                if (this.isStreaming) {
                    this.stopStreaming();
                    setTimeout(() => {
                        this.connectWebSocket();
                        setTimeout(() => this.startStreaming(), 2000);
                    }, 1000);
                } else if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                    // Just reconnect WebSocket with new language settings
                    this.websocket.close();
                    setTimeout(() => this.connectWebSocket(), 1000);
                }
            }
            
            updateStatus(message, type) {
                console.log(`üì± Status update [${type.toUpperCase()}]:`, message);
                this.statusMessage.textContent = message;
                this.statusMessage.className = `status ${type}`;
            }
            
            updateConnectionStatus(status) {
                const statusText = status === 'connected' ? 'Connected' : 
                                 status === 'connecting' ? 'Connecting...' : 'Disconnected';
                console.log('üîó Connection status changed to:', statusText);
                
                this.connectionStatus.textContent = statusText;
                this.connectionStatus.className = `connection-status ${status}`;
            }
        }
        
        // Initialize the translator when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new SpeechTranslator();
        });
    </script>
</body>
</html>