<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Speech Translation</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        
        .container {
            background: white;
            padding: 30px;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        }
        
        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
        }
        
        .controls {
            display: flex;
            flex-direction: column;
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .language-controls {
            display: grid;
            grid-template-columns: 1fr auto 1fr;
            gap: 15px;
            align-items: center;
        }
        
        .language-select {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        
        label {
            font-weight: 600;
            color: #555;
        }
        
        select {
            padding: 10px;
            border: 2px solid #ddd;
            border-radius: 6px;
            font-size: 16px;
            background: white;
        }
        
        .swap-btn {
            background: #007bff;
            color: white;
            border: none;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            cursor: pointer;
            font-size: 18px;
            transition: background-color 0.3s;
        }
        
        .swap-btn:hover {
            background: #0056b3;
        }
        
        .record-controls {
            text-align: center;
        }
        
        .record-btn {
            background: #28a745;
            color: white;
            border: none;
            padding: 15px 30px;
            font-size: 18px;
            border-radius: 8px;
            cursor: pointer;
            transition: background-color 0.3s;
            margin: 0 10px;
        }
        
        .record-btn:hover {
            background: #1e7e34;
        }
        
        .record-btn.recording {
            background: #dc3545;
            animation: pulse 1.5s infinite;
        }
        
        .record-btn.recording:hover {
            background: #c82333;
        }
        
        .record-btn:disabled {
            background: #6c757d;
            cursor: not-allowed;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        .status {
            text-align: center;
            padding: 15px;
            margin: 20px 0;
            border-radius: 6px;
            font-weight: 500;
        }
        
        .status.info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }
        
        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .status.warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        
        .audio-controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 20px 0;
        }
        
        .volume-control {
            display: flex;
            align-items: center;
            gap: 10px;
        }
        
        .volume-slider {
            width: 100px;
        }
        
        .connection-status {
            position: absolute;
            top: 10px;
            right: 10px;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 12px;
            font-weight: bold;
        }
        
        .connection-status.connected {
            background: #28a745;
            color: white;
        }
        
        .connection-status.disconnected {
            background: #dc3545;
            color: white;
        }
        
        .connection-status.connecting {
            background: #ffc107;
            color: black;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="connection-status" id="connectionStatus">Connecting...</div>
        
        <h1>üó£Ô∏è Real-time Speech Translation</h1>
        <p style="text-align: center; color: #666; margin-bottom: 30px;">
            English ‚Üî Bangla Speech-to-Speech Translation
        </p>
        
        <div class="controls">
            <div class="language-controls">
                <div class="language-select">
                    <label for="sourceLanguage">From:</label>
                    <select id="sourceLanguage">
                        <option value="eng">English</option>
                        <option value="ben">Bangla</option>
                    </select>
                </div>
                
                <button class="swap-btn" id="swapBtn" title="Swap languages">‚áÑ</button>
                
                <div class="language-select">
                    <label for="targetLanguage">To:</label>
                    <select id="targetLanguage">
                        <option value="ben">Bangla</option>
                        <option value="eng">English</option>
                    </select>
                </div>
            </div>
            
            <div class="mode-selection" style="text-align: center; margin-bottom: 20px;">
                <label style="margin-right: 20px;">
                    <input type="radio" name="mode" value="complete" checked> Complete Recording
                </label>
                <label>
                    <input type="radio" name="mode" value="streaming"> Continuous Streaming
                </label>
            </div>
            
            <div class="record-controls">
                <button class="record-btn" id="recordBtn">üé§ Start Recording</button>
                <button class="record-btn" id="stopBtn" style="display: none;">‚èπÔ∏è Stop</button>
                <button class="record-btn" id="streamBtn" style="display: none;">üåä Start Streaming</button>
            </div>
            
            <div class="audio-controls">
                <div class="volume-control">
                    <label for="outputVolume">Volume:</label>
                    <input type="range" id="outputVolume" class="volume-slider" min="0" max="1" step="0.1" value="0.8">
                    <span id="volumeValue">80%</span>
                </div>
            </div>
        </div>
        
        <div class="status info" id="statusMessage">
            Click "Start Recording" to begin real-time translation
        </div>
    </div>

    <script>
        class SpeechTranslator {
            constructor() {
                this.websocket = null;
                this.mediaRecorder = null;
                this.audioStream = null;
                this.isRecording = false;
                this.isStreaming = false;
                this.streamingMode = 'complete'; // 'complete' or 'streaming'
                this.audioContext = null;
                this.currentAudioSource = null;
                this.currentSessionId = null;
                this.playedSessionIds = new Set();
                this.lastAudioSize = 0;
                this.lastAudioTime = 0;
                this.clientId = Math.random().toString(36).substr(2, 9);
                this.outputVolume = 0.8;
                this.streamingProcessor = null;
                this.audioWorkletNode = null;
                
                this.initializeUI();
                this.connectWebSocket();
                this.enableAudioPlayback();
            }
            
            enableAudioPlayback() {
                let audioEnabled = false;
                console.log('üéµ Setting up audio playback enablement...');
                
                // Enable audio playback on first user interaction
                const enableAudio = async () => {
                    if (audioEnabled) {
                        console.log('üéµ Audio already enabled, skipping');
                        return;
                    }
                    
                    console.log('üëÜ User interaction detected - enabling audio...');
                    
                    try {
                        if (!this.audioContext) {
                            console.log('üéµ Creating AudioContext for user interaction...');
                            this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                                sampleRate: 16000
                            });
                        }
                        
                        console.log('üéµ AudioContext state before resume:', this.audioContext.state);
                        if (this.audioContext.state === 'suspended') {
                            await this.audioContext.resume();
                            console.log('‚úÖ AudioContext resumed from user interaction');
                        }
                        
                        audioEnabled = true;
                        console.log('üéâ Audio playback fully enabled!');
                        this.updateStatus('Audio enabled! Ready for translation', 'success');
                        
                        // Remove the event listeners after first interaction
                        document.removeEventListener('click', enableAudio);
                        document.removeEventListener('touchstart', enableAudio);
                        console.log('üóëÔ∏è Audio enablement event listeners removed');
                        
                    } catch (error) {
                        console.error('‚ùå Failed to enable audio:', error);
                        console.error('Audio enable error details:', error.stack);
                        this.updateStatus('Audio setup failed - please refresh and try again', 'error');
                    }
                };
                
                // Add event listeners for user interaction
                console.log('üëÇ Adding click/touch listeners for audio enablement');
                document.addEventListener('click', enableAudio);
                document.addEventListener('touchstart', enableAudio);
                
                // Show initial message
                this.updateStatus('Click anywhere to enable audio playback', 'warning');
            }
            
            initializeUI() {
                this.recordBtn = document.getElementById('recordBtn');
                this.stopBtn = document.getElementById('stopBtn');
                this.streamBtn = document.getElementById('streamBtn');
                this.swapBtn = document.getElementById('swapBtn');
                this.sourceLanguage = document.getElementById('sourceLanguage');
                this.targetLanguage = document.getElementById('targetLanguage');
                this.statusMessage = document.getElementById('statusMessage');
                this.connectionStatus = document.getElementById('connectionStatus');
                this.outputVolumeSlider = document.getElementById('outputVolume');
                this.volumeValue = document.getElementById('volumeValue');
                this.modeRadios = document.querySelectorAll('input[name="mode"]');
                
                this.recordBtn.addEventListener('click', () => this.startRecording());
                this.stopBtn.addEventListener('click', () => this.stopRecording());
                this.streamBtn.addEventListener('click', () => this.toggleStreaming());
                this.swapBtn.addEventListener('click', () => this.swapLanguages());
                
                // Mode selection
                this.modeRadios.forEach(radio => {
                    radio.addEventListener('change', (e) => {
                        this.streamingMode = e.target.value;
                        this.updateUIForMode();
                        
                        // Reconnect WebSocket with appropriate endpoint
                        if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                            this.websocket.close();
                            setTimeout(() => this.connectWebSocket(), 1000);
                        }
                    });
                });
                
                this.outputVolumeSlider.addEventListener('input', (e) => {
                    this.outputVolume = parseFloat(e.target.value);
                    this.volumeValue.textContent = `${Math.round(this.outputVolume * 100)}%`;
                });
                
                // Initial UI state
                this.updateUIForMode();
            }
            
            updateUIForMode() {
                if (this.streamingMode === 'streaming') {
                    this.recordBtn.style.display = 'none';
                    this.streamBtn.style.display = 'inline-block';
                    this.updateStatus('Click "Start Streaming" for continuous real-time translation', 'info');
                } else {
                    this.recordBtn.style.display = 'inline-block';
                    this.streamBtn.style.display = 'none';
                    this.updateStatus('Click "Start Recording" to record and translate complete phrases', 'info');
                }
            }
            
            connectWebSocket() {
                const wsUrl = this.streamingMode === 'streaming' ? 
                    'wss://34.81.26.139:7860/ws/stream' : 
                    'wss://34.81.26.139:7860/ws/translate';
                
                console.log('üîó Attempting WebSocket connection to:', wsUrl, 'Mode:', this.streamingMode);
                this.updateStatus('Connecting to server...', 'info');
                this.updateConnectionStatus('connecting');
                
                this.websocket = new WebSocket(wsUrl);
                
                this.websocket.onopen = () => {
                    console.log('‚úÖ WebSocket connected successfully');
                    
                    // Send appropriate start message based on mode
                    const startMessage = this.streamingMode === 'streaming' ? {
                        type: "start_stream",
                        src_lang: this.sourceLanguage.value,
                        tgt_lang: this.targetLanguage.value,
                        sample_rate: 16000,
                        chunk_size: 1024
                    } : {
                        type: "start",
                        src_lang: this.sourceLanguage.value,
                        tgt_lang: this.targetLanguage.value,
                        sample_rate: 16000,
                        format: "pcm_s16le"
                    };
                    
                    console.log('üì§ Sending start message:', startMessage);
                    this.websocket.send(JSON.stringify(startMessage));
                };
                
                this.websocket.onmessage = (event) => {
                    console.log('üì• WebSocket message received, type:', typeof event.data, 'size:', event.data.size || event.data.length);
                    
                    if (typeof event.data === 'string') {
                        // Handle JSON control messages
                        console.log('üìÑ JSON message received:', event.data);
                        try {
                            const msg = JSON.parse(event.data);
                            if (msg.type === 'ready' || msg.type === 'stream_ready') {
                                console.log('üü¢ Session ready - translation system active');
                                this.updateStatus('Connected! Ready to translate.', 'success');
                                this.updateConnectionStatus('connected');
                                this.recordBtn.disabled = false;
                                this.streamBtn.disabled = false;
                            } else if (msg.type === 'error') {
                                console.error('‚ùå Server error:', msg.msg);
                                this.updateStatus('Server error: ' + msg.msg, 'error');
                            } else if (msg.type === 'stream_end') {
                                console.log('üèÅ Streaming session ended');
                                this.isStreaming = false;
                                this.updateUIForStreaming(false);
                            } else {
                                console.log('‚ÑπÔ∏è Other server message:', msg);
                            }
                        } catch (e) {
                            console.error('‚ùå Failed to parse server message:', e, 'Raw data:', event.data);
                        }
                    } else {
                        // Handle binary audio data (raw PCM)
                        if (!this.isRecording || this.isStreaming) {
                            console.log('üéµ Binary audio data received for playback');
                            this.playTranslatedAudio(event.data);
                        } else {
                            console.log('üîá Ignoring audio response during active recording');
                        }
                    }
                };
                
                this.websocket.onclose = (event) => {
                    console.log('üî¥ WebSocket disconnected - Code:', event.code, 'Reason:', event.reason, 'Clean:', event.wasClean);
                    this.updateStatus('Disconnected from server. Trying to reconnect...', 'error');
                    this.updateConnectionStatus('disconnected');
                    this.recordBtn.disabled = true;
                    this.streamBtn.disabled = true;
                    
                    // Try to reconnect after 3 seconds
                    console.log('‚è±Ô∏è Reconnecting in 3 seconds...');
                    setTimeout(() => this.connectWebSocket(), 3000);
                };
                
                this.websocket.onerror = (error) => {
                    console.error('‚ùå WebSocket error occurred:', error);
                    console.error('Error details:', {
                        type: error.type,
                        target: error.target?.readyState,
                        timestamp: new Date().toISOString()
                    });
                    this.updateStatus('Connection error. Please check your network.', 'error');
                    this.updateConnectionStatus('disconnected');
                };
            }
            
            async handleWebSocketMessage(event) {
                if (event.data instanceof Blob) {
                    // Handle binary audio data
                    const arrayBuffer = await event.data.arrayBuffer();
                    const dataView = new DataView(arrayBuffer);
                    
                    // Read header length (first 4 bytes)
                    const headerLength = dataView.getUint32(0, true);
                    
                    // Parse header
                    const headerBytes = new Uint8Array(arrayBuffer, 4, headerLength);
                    const headerText = new TextDecoder().decode(headerBytes);
                    const header = JSON.parse(headerText);
                    
                    if (header.type === 'audio') {
                        // Extract audio data
                        const audioData = arrayBuffer.slice(4 + headerLength);
                        await this.playAudio(audioData);
                        this.updateStatus(`Playing translated audio (${header.src_lang} ‚Üí ${header.tgt_lang})`, 'success');
                    }
                } else {
                    // Handle text messages
                    const message = JSON.parse(event.data);
                    if (message.type === 'error') {
                        this.updateStatus(`Error: ${message.message}`, 'error');
                    }
                }
            }
            
            async playAudio(audioArrayBuffer) {
                try {
                    if (!this.audioContext) {
                        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    }
                    
                    const audioBuffer = await this.audioContext.decodeAudioData(audioArrayBuffer);
                    const source = this.audioContext.createBufferSource();
                    const gainNode = this.audioContext.createGain();
                    
                    source.buffer = audioBuffer;
                    gainNode.gain.value = this.outputVolume;
                    
                    source.connect(gainNode);
                    gainNode.connect(this.audioContext.destination);
                    
                    source.start();
                    
                } catch (error) {
                    console.error('Audio playback error:', error);
                    this.updateStatus('Audio playback failed', 'error');
                }
            }
            
            async startRecording() {
                try {
                    // Stop any current audio and reset state
                    if (this.currentAudioSource) {
                        this.currentAudioSource.stop();
                        this.currentAudioSource = null;
                    }
                    
                    // Generate new session ID for this recording
                    this.currentSessionId = Math.random().toString(36).substr(2, 9);
                    console.log('üÜî Starting new recording session:', this.currentSessionId);
                    console.log('üßπ Reset audio state for new session');
                    
                    console.log('üé§ Requesting microphone access...');
                    this.audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true
                        }
                    });
                    
                    console.log('‚úÖ Microphone access granted, stream tracks:', this.audioStream.getTracks().length);
                    
                    // Chrome only supports WebM, but we'll use the most compatible version
                    let options = { mimeType: 'audio/webm' };  // Most basic WebM format
                    
                    // Try specific codec for better compatibility
                    if (MediaRecorder.isTypeSupported('audio/webm;codecs=pcm')) {
                        options = { mimeType: 'audio/webm;codecs=pcm' };
                        console.log('‚úÖ Using WebM with PCM codec for easier processing');
                    } else if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
                        options = { mimeType: 'audio/webm;codecs=opus' };
                        console.log('‚úÖ Using WebM with Opus codec');
                    } else {
                        console.log('‚úÖ Using basic WebM format');
                    }
                    
                    console.log('üéôÔ∏è Creating MediaRecorder with options:', options);
                    this.mediaRecorder = new MediaRecorder(this.audioStream, options);
                    
                    // Store audio chunks for complete recording
                    this.audioChunks = [];
                    
                    this.mediaRecorder.ondataavailable = (event) => {
                        if (event.data.size > 0) {
                            console.log('üìä Audio chunk collected:', event.data.size, 'bytes, MIME type:', event.data.type);
                            this.audioChunks.push(event.data);
                        }
                    };
                    
                    this.mediaRecorder.onstop = () => {
                        console.log('üé¨ Recording stopped, processing complete audio...');
                        if (this.audioChunks.length > 0) {
                            const completeAudio = new Blob(this.audioChunks, { type: this.audioChunks[0].type });
                            console.log('üì¶ Complete audio blob created:', completeAudio.size, 'bytes');
                            
                            // Add small delay to ensure clean processing
                            setTimeout(() => {
                                this.convertAndSendAudio(completeAudio);
                            }, 100);
                        }
                        this.audioChunks = [];
                    };
                    
                    this.mediaRecorder.onerror = (event) => {
                        console.error('‚ùå MediaRecorder error:', event);
                        console.error('Error details:', {
                            error: event.error,
                            type: event.type,
                            timestamp: new Date().toISOString()
                        });
                        this.updateStatus('Recording error: ' + event.error, 'error');
                    };
                    
                    console.log('üé¨ Starting MediaRecorder for complete recording');
                    this.mediaRecorder.start(); // Record continuously until stopped
                    this.isRecording = true;
                    
                    this.recordBtn.style.display = 'none';
                    this.stopBtn.style.display = 'inline-block';
                    this.recordBtn.classList.add('recording');
                    
                    console.log('üî¥ Recording started - UI updated');
                    this.updateStatus('üé§ Recording... Speak now!', 'info');
                    
                } catch (error) {
                    console.error('Recording error:', error);
                    this.updateStatus('Microphone access denied or not available', 'error');
                }
            }
            
            stopRecording() {
                console.log('‚èπÔ∏è Stopping recording session:', this.currentSessionId);
                
                if (this.mediaRecorder && this.isRecording) {
                    console.log('üìä MediaRecorder state before stop:', this.mediaRecorder.state);
                    this.mediaRecorder.stop();
                    this.isRecording = false;
                    console.log('‚úÖ MediaRecorder stopped');
                }
                
                if (this.audioStream) {
                    console.log('üîá Stopping audio stream tracks:', this.audioStream.getTracks().length);
                    this.audioStream.getTracks().forEach(track => {
                        console.log('  - Stopping track:', track.kind, track.label);
                        track.stop();
                    });
                    this.audioStream = null;
                }
                
                this.recordBtn.style.display = 'inline-block';
                this.stopBtn.style.display = 'none';
                this.recordBtn.classList.remove('recording');
                
                console.log('üîÑ UI reset to ready state');
                this.updateStatus('Recording stopped. Click "Start Recording" to continue.', 'info');
            }
            
            async convertAndSendAudio(audioBlob) {
                try {
                    console.log('üîÑ Converting audio blob for transmission...');
                    console.log('üìä Blob details:', {
                        size: audioBlob.size,
                        type: audioBlob.type,
                        lastModified: audioBlob.lastModified || 'N/A'
                    });
                    
                    // For browser compatibility, send the original audio blob
                    // Backend will handle the format detection and conversion
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    console.log('üì§ Converted to ArrayBuffer:', arrayBuffer.byteLength, 'bytes');
                    
                    // Create a simple hash of the audio data to verify uniqueness
                    const audioHash = Array.from(new Uint8Array(arrayBuffer.slice(0, 100)))
                        .map(b => b.toString(16).padStart(2, '0')).join('').substring(0, 16);
                    console.log('üîç Audio fingerprint (first 100 bytes):', audioHash);
                    console.log('üéØ Session ID for this audio:', this.currentSessionId);
                    
                    // Verify WebSocket is still open
                    if (this.websocket.readyState !== WebSocket.OPEN) {
                        console.error('‚ùå WebSocket not open, state:', this.websocket.readyState);
                        this.updateStatus('Connection lost during send', 'error');
                        return;
                    }
                    
                    // Send the raw audio data to server for processing
                    console.log('üöÄ Sending audio data to server...');
                    this.websocket.send(arrayBuffer);
                    console.log('‚úÖ Audio data sent successfully');
                    this.updateStatus('Processing translation...', 'info');
                    
                } catch (error) {
                    console.error('‚ùå Error sending audio:', error);
                    console.error('Error stack:', error.stack);
                    this.updateStatus('Audio send error: ' + error.message, 'error');
                }
            }
            
            async playTranslatedAudio(audioData) {
                try {
                    const now = Date.now();
                    const audioSize = audioData.size || audioData.byteLength || 0;
                    
                    // Skip if we've already played audio for this session
                    if (this.currentSessionId && this.playedSessionIds.has(this.currentSessionId)) {
                        console.log('üîá Skipping duplicate audio for session:', this.currentSessionId);
                        return;
                    }
                    
                    // Skip if same size audio received within 2 seconds (likely duplicate)
                    if (audioSize === this.lastAudioSize && (now - this.lastAudioTime) < 2000) {
                        console.log('üîá Skipping likely duplicate audio - same size within 2s');
                        return;
                    }
                    
                    this.lastAudioSize = audioSize;
                    this.lastAudioTime = now;
                    
                    // Stop any currently playing audio to prevent overlapping
                    if (this.currentAudioSource) {
                        console.log('üõë Stopping previous audio to prevent overlap');
                        this.currentAudioSource.stop();
                        this.currentAudioSource = null;
                    }
                    
                    console.log('üéµ Processing audio for session:', this.currentSessionId);
                    console.log('Audio data type:', audioData.constructor.name);
                    
                    // Handle Blob vs ArrayBuffer
                    let arrayBuffer;
                    if (audioData instanceof Blob) {
                        console.log('Converting Blob to ArrayBuffer, size:', audioData.size, 'bytes');
                        arrayBuffer = await audioData.arrayBuffer();
                    } else if (audioData instanceof ArrayBuffer) {
                        console.log('Raw ArrayBuffer received:', audioData.byteLength, 'bytes');
                        arrayBuffer = audioData;
                    } else {
                        console.error('Unexpected audio data type:', typeof audioData);
                        this.updateStatus('Invalid audio data format', 'error');
                        return;
                    }
                    
                    console.log('Final ArrayBuffer size:', arrayBuffer.byteLength, 'bytes');
                    
                    // audioData is raw PCM bytes from server
                    const pcmArray = new Int16Array(arrayBuffer);
                    console.log('Converted to PCM array:', pcmArray.length, 'samples');
                    
                    if (pcmArray.length === 0) {
                        console.error('No PCM samples after conversion');
                        this.updateStatus('No audio data to play', 'error');
                        return;
                    }
                    
                    // Check for valid audio data (not all zeros)
                    const nonZeroSamples = pcmArray.filter(sample => sample !== 0).length;
                    console.log('Non-zero samples:', nonZeroSamples, 'out of', pcmArray.length);
                    
                    if (nonZeroSamples === 0) {
                        console.error('Audio data contains only silence');
                        this.updateStatus('Received silent audio - translation may have failed', 'error');
                        return;
                    }
                    
                    // Create or resume AudioContext
                    if (!this.audioContext) {
                        console.log('üéµ Creating new AudioContext with 16kHz sample rate');
                        this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                            sampleRate: 16000
                        });
                        console.log('‚úÖ AudioContext created, state:', this.audioContext.state);
                    }
                    
                    // Resume AudioContext if suspended (required by browser policy)
                    if (this.audioContext.state === 'suspended') {
                        console.log('‚è∏Ô∏è AudioContext suspended, attempting to resume...');
                        await this.audioContext.resume();
                        console.log('‚ñ∂Ô∏è AudioContext resumed, new state:', this.audioContext.state);
                    } else {
                        console.log('üîä AudioContext already active, state:', this.audioContext.state);
                    }
                    
                    // Convert PCM to AudioBuffer for playback
                    console.log('üéµ Creating AudioBuffer: 1 channel,', pcmArray.length, 'samples, 16kHz');
                    const audioBuffer = this.audioContext.createBuffer(1, pcmArray.length, 16000);
                    const channelData = audioBuffer.getChannelData(0);
                    console.log('üìä AudioBuffer created, duration:', audioBuffer.duration.toFixed(3), 'seconds');
                    
                    // Convert int16 to float32 and normalize
                    console.log('üîÑ Converting PCM int16 to float32...');
                    let minSample = 0, maxSample = 0;
                    for (let i = 0; i < pcmArray.length; i++) {
                        channelData[i] = Math.max(-1.0, Math.min(1.0, pcmArray[i] / 32768.0));
                        minSample = Math.min(minSample, channelData[i]);
                        maxSample = Math.max(maxSample, channelData[i]);
                    }
                    console.log('üìà Audio range after conversion: min =', minSample.toFixed(3), 'max =', maxSample.toFixed(3));
                    
                    // Create audio source and gain node
                    console.log('üéõÔ∏è Setting up audio graph...');
                    const source = this.audioContext.createBufferSource();
                    const gainNode = this.audioContext.createGain();
                    
                    source.buffer = audioBuffer;
                    gainNode.gain.value = this.outputVolume;
                    console.log('üîä Volume set to:', (this.outputVolume * 100).toFixed(0) + '%');
                    
                    // Connect audio graph
                    source.connect(gainNode);
                    gainNode.connect(this.audioContext.destination);
                    console.log('üîó Audio graph connected: Source ‚Üí Gain ‚Üí Destination');
                    
                    // Store reference to current audio source for stopping if needed
                    this.currentAudioSource = source;
                    
                    // Add event listeners
                    source.onended = () => {
                        console.log('üèÅ Audio playback finished successfully');
                        this.currentAudioSource = null;
                        this.updateStatus('Ready for next translation', 'success');
                    };
                    
                    source.onerror = (error) => {
                        console.error('‚ùå Audio source error:', error);
                        this.currentAudioSource = null;
                    };
                    
                    // Mark this session as played to prevent duplicates
                    if (this.currentSessionId) {
                        this.playedSessionIds.add(this.currentSessionId);
                        console.log('‚úÖ Marked session as played:', this.currentSessionId);
                        
                        // Clean up old session IDs to prevent memory growth
                        if (this.playedSessionIds.size > 10) {
                            const oldestId = this.playedSessionIds.values().next().value;
                            this.playedSessionIds.delete(oldestId);
                        }
                    }
                    
                    // Start playback
                    console.log('‚ñ∂Ô∏è Starting audio playback...');
                    source.start(0);
                    
                    console.log('üéµ Playing translated audio:', audioBuffer.duration.toFixed(2), 'seconds');
                    this.updateStatus(`üîä Playing translation (${audioBuffer.duration.toFixed(1)}s, Session: ${this.currentSessionId})`, 'success');
                    
                } catch (error) {
                    console.error('Audio playback error:', error);
                    this.updateStatus(`Playback error: ${error.message}`, 'error');
                    
                    // Detailed error logging
                    if (error.name === 'NotAllowedError') {
                        console.error('Audio playback not allowed - user interaction required');
                        this.updateStatus('Click to enable audio playback', 'error');
                    } else if (error.name === 'NotSupportedError') {
                        console.error('Audio format not supported');
                        this.updateStatus('Audio format not supported by browser', 'error');
                    }
                }
            }
            
            async sendAudioData(audioBlob) {
                try {
                    const arrayBuffer = await audioBlob.arrayBuffer();
                    
                    // Create header
                    const header = {
                        src_lang: this.sourceLanguage.value,
                        tgt_lang: this.targetLanguage.value
                    };
                    
                    const headerBytes = new TextEncoder().encode(JSON.stringify(header));
                    const headerLengthBytes = new Uint8Array(4);
                    const dataView = new DataView(headerLengthBytes.buffer);
                    dataView.setUint32(0, headerBytes.length, true);
                    
                    // Combine header length + header + audio data
                    const message = new Uint8Array(4 + headerBytes.length + arrayBuffer.byteLength);
                    message.set(headerLengthBytes, 0);
                    message.set(headerBytes, 4);
                    message.set(new Uint8Array(arrayBuffer), 4 + headerBytes.length);
                    
                    this.websocket.send(message);
                    this.updateStatus('Processing translation...', 'info');
                    
                } catch (error) {
                    console.error('Send audio error:', error);
                    this.updateStatus('Failed to send audio data', 'error');
                }
            }
            
            async toggleStreaming() {
                if (!this.isStreaming) {
                    await this.startStreaming();
                } else {
                    this.stopStreaming();
                }
            }
            
            async startStreaming() {
                try {
                    console.log('üåä Starting continuous streaming...');
                    
                    // Get microphone access
                    this.audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 16000,
                            channelCount: 1,
                            echoCancellation: true,
                            noiseSuppression: true,
                            autoGainControl: false
                        }
                    });
                    
                    console.log('‚úÖ Microphone access granted for streaming');
                    
                    // Create AudioContext for processing
                    if (!this.audioContext) {
                        this.audioContext = new (window.AudioContext || window.webkitAudioContext)({
                            sampleRate: 16000
                        });
                    }
                    
                    if (this.audioContext.state === 'suspended') {
                        await this.audioContext.resume();
                    }
                    
                    // Create MediaStreamAudioSourceNode
                    const source = this.audioContext.createMediaStreamSource(this.audioStream);
                    
                    // Create ScriptProcessorNode for audio processing (fallback for older browsers)
                    const processor = this.audioContext.createScriptProcessor(1024, 1, 1);
                    
                    processor.onaudioprocess = (event) => {
                        if (this.isStreaming && this.websocket.readyState === WebSocket.OPEN) {
                            const inputData = event.inputBuffer.getChannelData(0);
                            
                            // Convert float32 to int16
                            const int16Data = new Int16Array(inputData.length);
                            for (let i = 0; i < inputData.length; i++) {
                                int16Data[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32767));
                            }
                            
                            // Send audio chunk to server
                            this.websocket.send(int16Data.buffer);
                        }
                    };
                    
                    // Connect audio graph
                    source.connect(processor);
                    processor.connect(this.audioContext.destination);
                    
                    this.streamingProcessor = processor;
                    this.isStreaming = true;
                    this.updateUIForStreaming(true);
                    
                    console.log('üåä Streaming started successfully');
                    this.updateStatus('üåä Streaming... Speak continuously!', 'info');
                    
                } catch (error) {
                    console.error('Streaming error:', error);
                    this.updateStatus('Microphone access denied or streaming setup failed', 'error');
                }
            }
            
            stopStreaming() {
                console.log('‚èπÔ∏è Stopping streaming...');
                
                this.isStreaming = false;
                
                if (this.streamingProcessor) {
                    this.streamingProcessor.disconnect();
                    this.streamingProcessor = null;
                }
                
                if (this.audioStream) {
                    this.audioStream.getTracks().forEach(track => track.stop());
                    this.audioStream = null;
                }
                
                // Send stop message to server
                if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                    this.websocket.send(JSON.stringify({ type: "stop_stream" }));
                }
                
                this.updateUIForStreaming(false);
                console.log('‚úÖ Streaming stopped');
                this.updateStatus('Streaming stopped. Click "Start Streaming" to resume.', 'info');
            }
            
            updateUIForStreaming(isActive) {
                if (isActive) {
                    this.streamBtn.textContent = '‚èπÔ∏è Stop Streaming';
                    this.streamBtn.classList.add('recording');
                    this.modeRadios.forEach(radio => radio.disabled = true);
                } else {
                    this.streamBtn.textContent = 'üåä Start Streaming';
                    this.streamBtn.classList.remove('recording');
                    this.modeRadios.forEach(radio => radio.disabled = false);
                }
            }
            
            swapLanguages() {
                const sourceValue = this.sourceLanguage.value;
                const targetValue = this.targetLanguage.value;
                
                console.log('üîÑ Swapping languages:', sourceValue, '‚ÜîÔ∏è', targetValue);
                
                this.sourceLanguage.value = targetValue;
                this.targetLanguage.value = sourceValue;
                
                console.log('‚úÖ Languages swapped successfully');
                this.updateStatus('Languages swapped!', 'info');
                
                // Reconnect WebSocket with new language settings if connected
                if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                    this.websocket.close();
                    setTimeout(() => this.connectWebSocket(), 1000);
                }
            }
            
            updateStatus(message, type) {
                console.log(`üì± Status update [${type.toUpperCase()}]:`, message);
                this.statusMessage.textContent = message;
                this.statusMessage.className = `status ${type}`;
            }
            
            updateConnectionStatus(status) {
                const statusText = status === 'connected' ? 'Connected' : 
                                 status === 'connecting' ? 'Connecting...' : 'Disconnected';
                console.log('üîó Connection status changed to:', statusText);
                
                this.connectionStatus.textContent = statusText;
                this.connectionStatus.className = `connection-status ${status}`;
            }
        }
        
        // Initialize the translator when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new SpeechTranslator();
        });
    </script>
</body>
</html>